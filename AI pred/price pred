import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_percentage_error
from prophet import Prophet
import warnings

warnings.filterwarnings('ignore')

# 1. Load Data
current_dir = os.path.dirname(os.path.abspath(__file__))
file_path = os.path.join(current_dir, 'preprocessing_data.csv')
df = pd.read_csv(file_path)
df['date'] = pd.to_datetime(df['date'])
df = df.sort_values('date')

# 2. Feature Engineering
def add_full_features(df):
    for col in ['mean', 'max_amount', 'min_amount', 'total_quantity']:
        df[f'{col}_lag1'] = df[col].shift(1)
        df[f'{col}_lag7'] = df[col].shift(7)
    df['dayofweek'] = df['date'].dt.dayofweek
    df['month'] = df['date'].dt.month
    df['is_monday'] = (df['dayofweek'] == 0).astype(int)
    return df

df = add_full_features(df)

targets = {
    'mean_t1': 'Average Price (Mean)',
    'max_amount_t1': 'Maximum Price (Max)',
    'min_amount_t1': 'Minimum Price (Min)'
}

for t in targets.keys():
    base_col = t.replace('_t1', '')
    if t not in df.columns:
        df[t] = df[base_col].shift(-1)

# 3. Optimized Hyperparameters
best_params = {
    'n_estimators': 1200,
    'learning_rate': 0.005,
    'max_depth': 5,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'reg_lambda': 3.0,
    'random_state': 42
}

# Visualization Setup
fig, axes = plt.subplots(3, 1, figsize=(15, 18))
test_results = {}

# 4. Modeling Loop with 3-Month Test Split
for i, (target_col, target_name) in enumerate(targets.items()):
    print(f"ğŸš€ Training Model for: {target_name} (3-Month Validation)...")
    
    # Prophet guide
    base_col = target_col.replace('_t1', '')
    df_p = df[['date', base_col]].rename(columns={'date': 'ds', base_col: 'y'})
    m = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)
    m.add_country_holidays(country_name='KR')
    m.fit(df_p)
    df[f'prophet_{base_col}'] = m.predict(df_p[['ds']])['yhat'].values

    # Feature Preparation
    features = ['total_quantity', 'mean', 'max_amount', 'min_amount', 'dayofweek', 'is_monday', 
                'month', 'mean_lag1', 'max_amount_lag1', 'min_amount_lag1', f'prophet_{base_col}']
    
    df_ml = df.dropna(subset=[target_col] + features).copy()
    
    # --- [í•µì‹¬ ìˆ˜ì •] ìµœê·¼ 3ê°œì›”(ì•½ 90ì¼) í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ ---
    test_size = 90 
    train_df = df_ml.iloc[:-test_size]
    test_df = df_ml.iloc[-test_size:]

    X_train, y_train = train_df[features], np.log1p(train_df[target_col])
    X_test, y_actual = test_df[features], test_df[target_col]

    # Model Training
    model = XGBRegressor(**best_params)
    model.fit(X_train, y_train)

    # Prediction (Test on Unseen 90 days)
    y_pred = np.expm1(model.predict(X_test))
    
    # Calculate Error
    mape = mean_absolute_percentage_error(y_actual, y_pred)
    test_results[target_name] = mape * 100

    # 5. Visualization
    ax = axes[i]
    ax.plot(df_ml['date'], df_ml[target_col], label='Actual (Full)', color='black', alpha=0.1, linestyle=':')
    ax.plot(test_df['date'], y_actual, label='Actual (3-Month Test)', color='black', alpha=0.6)
    
    line_color = 'blue' if 'Mean' in target_name else ('red' if 'Max' in target_name else 'green')
    ax.plot(test_df['date'], y_pred, label='AI Prediction', color=line_color, linewidth=2.5)
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ê²½ê³„ì„  í‘œì‹œ
    ax.axvline(x=test_df['date'].iloc[0], color='gray', linestyle='--', alpha=0.5)
    ax.text(test_df['date'].iloc[0], ax.get_ylim()[1]*0.9, '   â† Train | Test(3M) â†’', color='gray')

    ax.set_title(f'{target_name} | Recent 3-Month MAPE: {test_results[target_name]:.2f}%', fontsize=11)
    ax.legend(loc='upper left')
    ax.grid(True, alpha=0.2)

plt.xlabel('Date')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Final Summary Report
print("\n" + "="*55)
print("ğŸ“Š RECENT 3-MONTH TEST PERFORMANCE REPORT")
print("="*55)
for name, error in test_results.items():
    print(f"âœ… {name:25s}: {error:.2f}%")
print("="*55)
